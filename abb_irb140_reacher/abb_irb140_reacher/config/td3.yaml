model_params:

  # Training 
  training_steps: 2000000      # The number of training steps to perform

  # Save params
  save_freq: 100000
  save_prefix: td3_model
  trained_model_name: trained_model_new
  save_replay_buffer: True

  # Load model params
  load_model: False
  model_name: trained_model_01_12_2021_06_38_40

  # Logging parameters
  log_folder: TD3_New
  log_interval: 1 # The number of episodes between logs
  reset_num_timesteps: False # If true, will reset the number of timesteps to 0 every training 

  # Use custom policy - Only MlpPolicy is supported (Only used when new model is created)
  use_custom_policy: True
  policy_params:
    net_arch: [512, 512, 512] # List of hidden layer sizes
    activation_fn: relu  # relu, tanh, elu or selu
    features_extractor_class: FlattenExtractor # FlattenExtractor, BaseFeaturesExtractor or CombinedExtractor
    optimizer_class: Adam # Adam, Adadelta, Adagrad, RMSprop or SGD

  # UseAction noise
  use_action_noise: True # For now only Gaussian noise is supported
  action_noise:
    mean: 0.0
    sigma: 0.01

  # TD3 parameters
  td3_params:
    learning_rate: 0.001
    buffer_size: 1000000
    learning_starts: 1000000
    batch_size: 1000
    tau: 0.005
    gamma: 0.99
    gradient_steps: -1 #-1
    policy_delay: 2
    target_policy_noise: 0.2
    target_noise_clip: 0.5
    train_freq:
      freq: 1000
      unit: step  # episode or step